{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This code is imported from the following project: https://github.com/asmith26/wide_resnets_keras\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, add, Dense, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.backend import common as K\n",
    "\n",
    "sys.setrecursionlimit(2 ** 20)\n",
    "np.random.seed(2 ** 10)\n",
    "\n",
    "\n",
    "class WideResNet:\n",
    "    def __init__(self, image_size, depth=16, k=8):\n",
    "        self._depth = depth\n",
    "        self._k = k\n",
    "        self._dropout_probability = 0\n",
    "        self._weight_decay = 0.0005\n",
    "        self._use_bias = False\n",
    "        self._weight_init = \"he_normal\"\n",
    "\n",
    "        if K.image_data_format() == \"th\":\n",
    "            logging.debug(\"image_data_format = 'th'\")\n",
    "            self._channel_axis = 1\n",
    "            self._input_shape = (3, image_size, image_size)\n",
    "        else:\n",
    "            logging.debug(\"image_data_format = 'tf'\")\n",
    "            self._channel_axis = -1\n",
    "            self._input_shape = (image_size, image_size, 3)\n",
    "\n",
    "    # Wide residual network http://arxiv.org/abs/1605.07146\n",
    "    def _wide_basic(self, n_input_plane, n_output_plane, stride):\n",
    "        def f(net):\n",
    "            # format of conv_params:\n",
    "            #               [ [kernel_size=(\"kernel width\", \"kernel height\"),\n",
    "            #               strides=\"(stride_vertical,stride_horizontal)\",\n",
    "            #               padding=\"same\" or \"valid\"] ]\n",
    "            # B(3,3): orignal <<basic>> block\n",
    "            conv_params = [[3, 3, stride, \"same\"],\n",
    "                           [3, 3, (1, 1), \"same\"]]\n",
    "\n",
    "            n_bottleneck_plane = n_output_plane\n",
    "\n",
    "            # Residual block\n",
    "            for i, v in enumerate(conv_params):\n",
    "                if i == 0:\n",
    "                    if n_input_plane != n_output_plane:\n",
    "                        net = BatchNormalization(axis=self._channel_axis)(net)\n",
    "                        net = Activation(\"relu\")(net)\n",
    "                        convs = net\n",
    "                    else:\n",
    "                        convs = BatchNormalization(axis=self._channel_axis)(net)\n",
    "                        convs = Activation(\"relu\")(convs)\n",
    "\n",
    "                    convs = Conv2D(n_bottleneck_plane, kernel_size=(v[0], v[1]),\n",
    "                                          strides=v[2],\n",
    "                                          padding=v[3],\n",
    "                                          kernel_initializer=self._weight_init,\n",
    "                                          kernel_regularizer=l2(self._weight_decay),\n",
    "                                          use_bias=self._use_bias)(convs)\n",
    "                else:\n",
    "                    convs = BatchNormalization(axis=self._channel_axis)(convs)\n",
    "                    convs = Activation(\"relu\")(convs)\n",
    "                    if self._dropout_probability > 0:\n",
    "                        convs = Dropout(self._dropout_probability)(convs)\n",
    "                    convs = Conv2D(n_bottleneck_plane, kernel_size=(v[0], v[1]),\n",
    "                                          strides=v[2],\n",
    "                                          padding=v[3],\n",
    "                                          kernel_initializer=self._weight_init,\n",
    "                                          kernel_regularizer=l2(self._weight_decay),\n",
    "                                          use_bias=self._use_bias)(convs)\n",
    "\n",
    "            # Shortcut Connection: identity function or 1x1 convolutional\n",
    "            #  (depends on difference between input & output shape - this\n",
    "            #   corresponds to whether we are using the first block in each\n",
    "            #   group; see _layer() ).\n",
    "            if n_input_plane != n_output_plane:\n",
    "                shortcut = Conv2D(n_output_plane, kernel_size=(1, 1),\n",
    "                                         strides=stride,\n",
    "                                         padding=\"same\",\n",
    "                                         kernel_initializer=self._weight_init,\n",
    "                                         kernel_regularizer=l2(self._weight_decay),\n",
    "                                         use_bias=self._use_bias)(net)\n",
    "            else:\n",
    "                shortcut = net\n",
    "\n",
    "            return add([convs, shortcut])\n",
    "\n",
    "        return f\n",
    "\n",
    "\n",
    "    # \"Stacking Residual Units on the same stage\"\n",
    "    def _layer(self, block, n_input_plane, n_output_plane, count, stride):\n",
    "        def f(net):\n",
    "            net = block(n_input_plane, n_output_plane, stride)(net)\n",
    "            for i in range(2, int(count + 1)):\n",
    "                net = block(n_output_plane, n_output_plane, stride=(1, 1))(net)\n",
    "            return net\n",
    "\n",
    "        return f\n",
    "\n",
    "#    def create_model(self):\n",
    "    def __call__(self):\n",
    "        logging.debug(\"Creating model...\")\n",
    "\n",
    "        assert ((self._depth - 4) % 6 == 0)\n",
    "        n = (self._depth - 4) / 6\n",
    "\n",
    "        inputs = Input(shape=self._input_shape)\n",
    "\n",
    "        n_stages = [16, 16 * self._k, 32 * self._k, 64 * self._k]\n",
    "\n",
    "        conv1 = Conv2D(filters=n_stages[0], kernel_size=(3, 3),\n",
    "                              strides=(1, 1),\n",
    "                              padding=\"same\",\n",
    "                              kernel_initializer=self._weight_init,\n",
    "                              kernel_regularizer=l2(self._weight_decay),\n",
    "                              use_bias=self._use_bias)(inputs)  # \"One conv at the beginning (spatial size: 32x32)\"\n",
    "\n",
    "        # Add wide residual blocks\n",
    "        block_fn = self._wide_basic\n",
    "        conv2 = self._layer(block_fn, n_input_plane=n_stages[0], n_output_plane=n_stages[1], count=n, stride=(1, 1))(conv1)\n",
    "        conv3 = self._layer(block_fn, n_input_plane=n_stages[1], n_output_plane=n_stages[2], count=n, stride=(2, 2))(conv2)\n",
    "        conv4 = self._layer(block_fn, n_input_plane=n_stages[2], n_output_plane=n_stages[3], count=n, stride=(2, 2))(conv3)\n",
    "        batch_norm = BatchNormalization(axis=self._channel_axis)(conv4)\n",
    "        relu = Activation(\"relu\")(batch_norm)\n",
    "\n",
    "        # Classifier block\n",
    "        pool = AveragePooling2D(pool_size=(8, 8), strides=(1, 1), padding=\"same\")(relu)\n",
    "        flatten = Flatten()(pool)\n",
    "        predictions_g = Dense(units=2, kernel_initializer=self._weight_init, use_bias=self._use_bias,\n",
    "                              kernel_regularizer=l2(self._weight_decay), activation=\"softmax\")(flatten)\n",
    "        predictions_a = Dense(units=101, kernel_initializer=self._weight_init, use_bias=self._use_bias,\n",
    "                              kernel_regularizer=l2(self._weight_decay), activation=\"softmax\")(flatten)\n",
    "\n",
    "        model = Model(inputs=inputs, outputs=[predictions_g, predictions_a])\n",
    "\n",
    "        return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
